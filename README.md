<h1 align="center">Goodreads Book Scraper</h1>

## Descrição do Projeto

Este projeto de Data Science utiliza Python e BeautifulSoup para realizar web scraping das avaliações e detalhes dos melhores livros do Goodreads. O objetivo é extrair informações como título, autor e avaliação dos livros destacados na lista "Best Books Ever" do Goodreads e salvar esses dados em um arquivo CSV para análise posterior.

## Funcionalidade do Projeto

- Extração de dados de livros (título, autor, avaliação) da lista "Best Books Ever" do Goodreads
- Salvamento dos dados extraídos em um arquivo CSV
- Análise e visualização dos dados extraídos

## Tecnologias usadas no projeto

- Python
- BeautifulSoup (para web scraping)
- Pandas (para manipulação de dados)
- Matplotlib (para visualização de dados)

## Status do Projeto

O projeto está em fase de desenvolvimento. As funcionalidades básicas foram implementadas, mas ainda há melhorias e ajustes planejados, incluindo:

- Adição de mais campos de dados dos livros
- Melhorias na robustez do scraping (tratamento de erros, verificação de conectividade)
- Análises de dados mais avançadas

## Exemplos de uso do projeto

Aqui estão alguns exemplos visuais de como usar a aplicação:

![Plot da Distribuição das Avaliações](images/rating_distribution.png)
*Figura 1: Plot da Distribuição das Avaliações*

## Colaboradores

<table>
  <tr>
    <td align="center">
      <a href="http://github.com/dafnirca">
        <img src="https://avatars.githubusercontent.com/u/109047245?v=4" width="100px;" alt="Foto de Dafni Rosa no GitHub"/><br>
        <sub>
          <b>dafnirca</b>
        </sub>
      </a>
    </td>
  </tr>
</table>

## Licença

Este projeto está licenciado sob a licença MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## Notas Adicionais

Para mais informações e documentação detalhada, visite nosso [site oficial](https://example.com).

### Links Úteis

- [Documentação Completa](https://example.com/docs)
- [Instruções de Uso](https://example.com/usage)
- [FAQ](https://example.com/faq)
